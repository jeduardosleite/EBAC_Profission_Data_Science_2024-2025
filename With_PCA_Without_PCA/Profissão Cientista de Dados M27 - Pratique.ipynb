{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cabec%CC%A7alho_notebook.png](cabecalho_notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA - Tarefa 01: *HAR* com PCA\n",
    "\n",
    "Vamos trabalhar com a base da demonstração feita em aula, mas vamos explorar um pouco melhor como é o desempenho da árvore variando o número de componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "filename_features = \"./Dados/UCI HAR Dataset/features.txt\"\n",
    "filename_labels   = \"./Dados/UCI HAR Dataset/activity_labels.txt\"\n",
    "\n",
    "filename_subtrain = \"./Dados/UCI HAR Dataset/train/subject_train.txt\"\n",
    "filename_xtrain   = \"./Dados/UCI HAR Dataset/train/X_train.txt\"\n",
    "filename_ytrain   = \"./Dados/UCI HAR Dataset/train/y_train.txt\"\n",
    "\n",
    "filename_subtest  = \"./Dados/UCI HAR Dataset/test/subject_test.txt\"\n",
    "filename_xtest    = \"./Dados/UCI HAR Dataset/test/X_test.txt\"\n",
    "filename_ytest    = \"./Dados/UCI HAR Dataset/test/y_test.txt\"\n",
    "\n",
    "# --- Features ---\n",
    "features = pd.read_csv(filename_features, sep=r\"\\s+\", header=None, names=['id', 'nome_var'])\n",
    "nomes_features = features['nome_var']\n",
    "\n",
    "# Corrige duplicatas nos nomes\n",
    "nomes_features = pd.Index(nomes_features)\n",
    "if nomes_features.duplicated().any():\n",
    "    nomes_features = nomes_features.to_series().where(~nomes_features.duplicated(),\n",
    "                                                      nomes_features.to_series() + \"_\" + nomes_features.to_series().groupby(nomes_features).cumcount().astype(str))\n",
    "\n",
    "nomes_features = nomes_features.tolist()\n",
    "\n",
    "# --- Labels ---\n",
    "labels = pd.read_csv(filename_labels, sep=r\"\\s+\", header=None, names=['cod_label', 'label'])\n",
    "\n",
    "# --- Conjunto de treino ---\n",
    "subject_train = pd.read_csv(filename_subtrain, header=None, names=['subject_id'])\n",
    "X_train = pd.read_csv(filename_xtrain, sep=r\"\\s+\", header=None, names=nomes_features)\n",
    "y_train = pd.read_csv(filename_ytrain, header=None, names=['cod_label'])\n",
    "\n",
    "# --- Conjunto de teste ---\n",
    "subject_test = pd.read_csv(filename_subtest, header=None, names=['subject_id'])\n",
    "X_test = pd.read_csv(filename_xtest, sep=r\"\\s+\", header=None, names=nomes_features)\n",
    "y_test = pd.read_csv(filename_ytest, header=None, names=['cod_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (7352, 561)\n",
      "X_test (2947, 561)\n",
      "y_train (7352, 1)\n",
      "y_test (2947, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train {X_train.shape}')\n",
    "print(f'X_test {X_test.shape}')\n",
    "print(f'y_train {y_train.shape}')\n",
    "print(f'y_test {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de decisão\n",
    "\n",
    "Rode uma árvore de decisão com todas as variáveis, utilizando o ```ccp_alpha=0.001```. Avalie a acurácia nas bases de treinamento e teste. Avalie o tempo de processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de treino:97.6\n",
      "Acurácia de teste:88.0\n",
      "\n",
      "CPU times: total: 4.02 s\n",
      "Wall time: 4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42,\n",
    "                             ccp_alpha=0.001).fit(X_train, y_train)\n",
    "\n",
    "train_score = clf.score(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "\n",
    "print(f'Acurácia de treino:{train_score*100:.1f}')\n",
    "print(f'Acurácia de teste:{test_score*100:.1f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore com PCA\n",
    "\n",
    "Faça uma análise de componemtes principais das variáveis originais. Utilize apenas uma componente. Faça uma árvore de decisão com esta componente como variável explicativa.\n",
    "\n",
    "- Avalie a acurácia nas bases de treinamento e teste\n",
    "- Avalie o tempo de processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do train_score_pca é 50.0\n",
      "Acurácia do test_score_pca é 45.7\n",
      "\n",
      "CPU times: total: 703 ms\n",
      "Wall time: 140 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prcomp = PCA(n_components=1).fit(X_train)\n",
    "\n",
    "X_pca_train = prcomp.transform(X_train)\n",
    "X_pca_test = prcomp.transform(X_test)\n",
    "\n",
    "pca_clf = DecisionTreeClassifier(random_state=42,\n",
    "                                 ccp_alpha=0.001).fit(X_pca_train, y_train)\n",
    "\n",
    "train_score_pca = pca_clf.score(X_pca_train, y_train)\n",
    "test_score_pca = pca_clf.score(X_pca_test, y_test)\n",
    "\n",
    "print(f'Acurácia do train_score_pca é {train_score_pca*100:.1f}')\n",
    "print(f'Acurácia do test_score_pca é {test_score_pca*100:.1f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o número de componentes\n",
    "\n",
    "Com base no código acima, teste a árvore de classificação com pelo menos as seguintes possibilidades de quantidades de componentes: ```[1, 2, 5, 10, 50]```. Avalie para cada uma delas:\n",
    "\n",
    "- Acurácia nas bases de treino e teste\n",
    "- Tempo de processamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'clf__ccp_alpha': 0.001, 'pca__n_components': 50}\n",
      "Acurácia no teste:82.3\n",
      "Acurácia no treino: 91.9\n",
      "CPU times: total: 2.08 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Garante que o PCA seja rodado dentro do GridSearch\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "grid_params = {\n",
    "    'pca__n_components': [1,2,5,10,50],\n",
    "    'clf__ccp_alpha': [0.0, 0.001, 0.01]}\n",
    "\n",
    "grid = GridSearchCV(pipe, grid_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid.best_params_)\n",
    "\n",
    "# Avaliar no conjunto de teste\n",
    "best_model = grid.best_estimator_\n",
    "test_score_grid = best_model.score(X_test, y_test)\n",
    "train_score_grid = best_model.score(X_train, y_train)\n",
    "print(f'Acurácia no teste:{test_score_grid*100:.1f}')\n",
    "print(f'Acurácia no treino: {train_score_grid*100:.1f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclua\n",
    "\n",
    "- O que aconteceu com a acurácia?\n",
    "- O que aconteceu com o tempo de processamento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Acurácia Treino</th>\n",
       "      <th>Acurácia Teste</th>\n",
       "      <th>Tempo Execução (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sem PCA</td>\n",
       "      <td>97.58%</td>\n",
       "      <td>87.99%</td>\n",
       "      <td>3.95s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Com PCA</td>\n",
       "      <td>89.27%</td>\n",
       "      <td>82.42%</td>\n",
       "      <td>3.32s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Modelo Acurácia Treino Acurácia Teste Tempo Execução (s)\n",
       "0  Sem PCA          97.58%         87.99%              3.95s\n",
       "1  Com PCA          89.27%         82.42%              3.32s"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "resultados = []\n",
    "\n",
    "# ----------------------\n",
    "# SEM PCA\n",
    "# ----------------------\n",
    "start = time.time()\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, ccp_alpha=0.001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_score = clf.score(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "resultados.append({\n",
    "    \"Modelo\": \"Sem PCA\",\n",
    "    \"Acurácia Treino\": f'{train_score*100:.2f}%',\n",
    "    \"Acurácia Teste\": f'{test_score*100:.2f}%',\n",
    "    \"Tempo Execução (s)\": f'{end - start:.2f}s'\n",
    "})\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# COM PCA (GridSearch)\n",
    "# ----------------------\n",
    "start = time.time()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "grid_params = {\n",
    "    'pca__n_components': [1, 2, 5, 10, 50],\n",
    "    'clf__ccp_alpha': [0.0, 0.001, 0.01]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, grid_params, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "train_score_grid = best_model.score(X_train, y_train)\n",
    "test_score_grid = best_model.score(X_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "resultados.append({\n",
    "    \"Modelo\": \"Com PCA\",\n",
    "    \"Acurácia Treino\": f\"{train_score_grid*100:.2f}%\",\n",
    "    \"Acurácia Teste\": f\"{test_score_grid*100:.2f}%\",\n",
    "    \"Tempo Execução (s)\": f\"{end - start:.2f}s\"\n",
    "})\n",
    "\n",
    "\n",
    "# ----------------------\n",
    "# Monta DataFrame\n",
    "# ----------------------\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretação\n",
    "\n",
    "### SEM PCA\n",
    "A acuracidade está maior, mas o tempo de execução é ligeiramente maior.\n",
    "\n",
    "### Com PCA\n",
    "A acuracidade caiu 8-5 pontos, mas o tempo foi menor\n",
    "\n",
    "---\n",
    "Isso exemplifica o dilema entre ```redução de dimensionalidade``` e ```perda de informação```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Índice",
   "title_sidebar": "Conteúdo",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
